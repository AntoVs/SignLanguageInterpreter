#  AI-Powered Sign Language Interpreter

This project is a lightweight, real-time Sign Language Interpreter that uses MediaPipe for hand tracking and a Machine Learning model to predict sign gestures. It is built with Python, Flask, OpenCV, and Socket.IO.

---

## ğŸš€ Features

-  Real-time hand gesture recognition using webcam
-  Trained ML model for alphabet and common sign classification
-  Web-based interface using Flask
-  Modular and customizable codebase
-  Offline 

---

#  System Architecture

User Hand â†’ Webcam â†’ MediaPipe (Hand Detection) â†’ Landmark Extraction â†’ Trained ML Model â†’ Prediction â†’ Flask Web App


---

## ğŸ› ï¸ Installation

```bash
# Clone the repo
git clone https://github.com/AntoVs/SignLanguageInterpreter.git
cd SignLanguageInterpreter

# Set up virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt
```

---

# Running the App

```bash
python app.py
#use ver 3.13.2
```

# License

This project user lisenced ai model under MIT lisence

# DEMO

![hello](https://github.com/user-attachments/assets/cb88b49a-3853-4699-899f-cc9eb737a212)

![ThankYou](https://github.com/user-attachments/assets/1b327703-3547-4880-b6d7-0d6c283ea758)

